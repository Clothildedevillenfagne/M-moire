{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PrefixSpan\n",
    "\n",
    "### Project a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation prise de https://github.com/sequenceanalysis/sequenceanalysis.github.io/blob/master/notebooks/part2.ipynb\n",
    "\"\"\"\n",
    "Projects a sequence according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    sequence: the sequence the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    If the sequence does not contain the prefix, then None.\n",
    "    Otherwise, a new sequence starting from the position of the prefix, including the itemset that includes the prefix\n",
    "\"\"\"\n",
    "def projectSequence(sequence, prefix, newEvent):\n",
    "    result = None\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if result is None:\n",
    "            if (not newEvent) or i > 0:\n",
    "                if (all(x in itemset for x in prefix)):\n",
    "                    result = [list(itemset)]\n",
    "        else:\n",
    "            result.append(copy.copy(itemset))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a dataset according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    dataset: the dataset the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    A (potentially empty) list of sequences\n",
    "\"\"\"\n",
    "def projectDatabase(dataset, prefix, newEvent):\n",
    "    projectedDB = []\n",
    "    for sequence in dataset:\n",
    "        seqProjected = projectSequence(sequence, prefix, newEvent)\n",
    "        if not seqProjected is None:\n",
    "            projectedDB.append(seqProjected)\n",
    "    return projectedDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a list of all items that are contained in a dataset\n",
    "\"\"\"\n",
    "def generateItems(dataset):\n",
    "    return sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "\n",
    "\"\"\"\n",
    "Computes a defaultdict that maps each item in the dataset to its support\n",
    "\"\"\"\n",
    "def generateItemSupports(dataset, ignoreFirstEvent=False, prefix=[]):\n",
    "    result = defaultdict(int)\n",
    "    for sequence in dataset:\n",
    "        if ignoreFirstEvent:\n",
    "            sequence = sequence[1:]\n",
    "        cooccurringItems = set()\n",
    "        for itemset in sequence:\n",
    "            if all(x in itemset for x in prefix):\n",
    "                for item in itemset:\n",
    "                    if not item in prefix:\n",
    "                        cooccurringItems.add(item)\n",
    "        for item in cooccurringItems:\n",
    "            result [item] += 1\n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The PrefixSpan algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def prefixSpan(dataset, minSupport):\n",
    "    result = []\n",
    "    itemCounts = generateItemSupports(dataset)\n",
    "    for item, count in itemCounts:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = [[item]]\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], False), minSupport, newPrefix))\n",
    "    return result\n",
    "\n",
    "def prefixSpanInternal(dataset, minSupport, prevPrefixes=[]):\n",
    "    result = []\n",
    "    \n",
    "    # Add a new item to the last element (==same time)\n",
    "    itemCountSameEvent = generateItemSupports(dataset, False, prefix=prevPrefixes[-1])\n",
    "    for item, count in itemCountSameEvent:\n",
    "        if (count >= minSupport) and item > prevPrefixes[-1][-1]:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix[-1].append(item)\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, newPrefix[-1], False), minSupport, newPrefix))\n",
    "        \n",
    "    # Add a new event to the prefix\n",
    "    itemCountSubsequentEvents = generateItemSupports(dataset, True)\n",
    "    for item, count in itemCountSubsequentEvents:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix.append([item])\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], True), minSupport, newPrefix))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Filter for closed and maximal patterns\n",
    "### Closed patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of closed frequent sequence (as a list)\n",
    "This is only a very simplistic (naive) implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterClosed(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence(supersequence, subsequence) and (countSeq == countSubSeq) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of maximal frequent sequence (as a list)\n",
    "This is only a very naive implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterMaximal(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence (supersequence, subsequence) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this to the list of list of lists that we use as a dataformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clothildedevillenfagne/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (9,10,14,16,17,37,38,39,40,41,43,44,45,46,48,49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'./moyen_data.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[df['class']=='Aves']\n",
    "new_df = new_df[['family','species', 'year', 'month', 'decimalLatitude', 'decimalLongitude', 'individualCount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarder pour les espèce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_for_year(df):\n",
    "    resultat_final=[]\n",
    "    #df_use = df[df['year']==annee]\n",
    "    year = set(df['year'].tolist())\n",
    "    #gen = list(set(df['species'].tolist()))\n",
    "    \n",
    "    for ye in year:\n",
    "        data1 = df[df.year == ye]\n",
    "        print('année :', ye)\n",
    "        #print(data1)\n",
    "        month = set(data1['month'].tolist())\n",
    "        new_month = []\n",
    "        count = False\n",
    "        for elem in month:\n",
    "            if pd.isnull(elem):\n",
    "                count = True\n",
    "            else:\n",
    "                new_month.append(elem)\n",
    "            if count == True:\n",
    "                new_month.append(float('nan'))\n",
    "        month = new_month\n",
    "        big_list =[]\n",
    "        for mo in month:\n",
    "            data2 = data1[data1.month == mo]\n",
    "            longitude = set(data2['decimalLongitude'].tolist())\n",
    "            print('mois :', mo)\n",
    "            for lon in longitude:\n",
    "                data3 = data2[data2.decimalLongitude == lon]\n",
    "                latitude = set(data3['decimalLatitude'].tolist())\n",
    "                for la in latitude:  # d'abord refaire un for pour longitude puis latitude\n",
    "                    lst = []#[0] * len(gen) #np.nan\n",
    "                    final_df = data3[data3.decimalLatitude == la]\n",
    "                    #print(final_df)\n",
    "                    # num_obs = len(final_df['decimalLatitude'])\n",
    "                    genre = set(final_df['species'].tolist())\n",
    "                    for elem in genre:\n",
    "                        if pd.isnull(elem) == False:\n",
    "                        #index = gen.index(elem)\n",
    "                        #lst[index]+=1\n",
    "                            lst.append(elem)\n",
    "\n",
    "                    big_list.append(lst)\n",
    "        wikispeediaData=[]\n",
    "        for seq in big_list:\n",
    "            newSeq = []\n",
    "            for item in seq:\n",
    "                newSeq.append([item])\n",
    "            wikispeediaData.append(newSeq)\n",
    "        min_sup = len(wikispeediaData)*10/100\n",
    "        res = prefixSpan (wikispeediaData, min_sup)\n",
    "        resultat = []\n",
    "        for elem in res:\n",
    "            resultat.append(elem+(ye,))\n",
    "        resultat_final.extend(resultat)\n",
    "    return resultat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = ps_for_year(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =[] \n",
    "for i in range(len(res)):\n",
    "    longueur = len(res[i][0])\n",
    "    pattern = []\n",
    "    for j in range(longueur):\n",
    "        elem = res[i][0][j][0]\n",
    "        pattern.append(elem)\n",
    "        b = frozenset(pattern)\n",
    "    c = (b, res[i][1], res[i][2])\n",
    "    final.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix = pd.DataFrame(final, columns =['espece', 'compte', 'annee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = []\n",
    "espece = set(df_prefix['espece'].tolist())\n",
    "for element in espece:\n",
    "    df_1 = df_prefix[df_prefix['espece']==element]\n",
    "    list_annee = []\n",
    "    list_count = []\n",
    "    for el in df_1.itertuples():\n",
    "        list_annee.append(el.annee)\n",
    "        list_count.append(el.compte)\n",
    "    list_pat = [element,df_1['compte'].sum() ,list_count, list_annee, len(set(list_annee))]\n",
    "    ar.append(list_pat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefixSpan = pd.DataFrame(ar, columns =['espèce', 'compte_total','compte', 'année', 'nombre_annee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prefix = df_prefixSpan.sort_values(['nombre_annee', 'compte_total'], ascending = [False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_prefix.to_csv('res_prefix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prefixSpan.sort_values(by = 'nombre_annee', ascending = [False])['compte_total'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outte = df_prefixSpan[df_prefixSpan['espèce']== frozenset(['Alopochen aegyptiaca'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_outte = df_outte['compte'].tolist()\n",
    "annee_ouette = df_outte['année'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(annee_ouette[0],count_outte[0])\n",
    "#plt.title(\"Nombre d'observation en fonction des années\")\n",
    "plt.xlabel('Années')\n",
    "plt.ylabel(\"Nombre d'observation\")\n",
    "plt.savefig(\"obs_annee.png\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voir ratio nombre d'observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = set(df['year'].tolist())\n",
    "dico_year = {}\n",
    "for ye in year:\n",
    "    data1 = df[df['year']==ye]\n",
    "    dico_year[ye]=len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dico_year.keys(),dico_year.values())\n",
    "plt.title(\"Nombre d'observation en fonction des années\")\n",
    "plt.xlabel('Années')\n",
    "plt.ylabel(\"Nombre d'observation)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dic = {}\n",
    "count = 0\n",
    "for key,value in dico_year.items():\n",
    "    new_dic[key] = (count_outte[0][count]/value)*100\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pourcentage d'observation des ouette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_dic.keys(),new_dic.values())\n",
    "plt.xlabel('Années')\n",
    "plt.ylabel(\"Observation(%)\")\n",
    "plt.savefig(\"rat_annee.png\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nombre d'ouette observer chaque année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = set(df['year'].tolist())\n",
    "dico_count = {}\n",
    "for ye in year:\n",
    "    data1 = df[df['year']==ye]\n",
    "    dico_count[ye]=len(data1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = set(new_df['year'].tolist())\n",
    "new_new_df = new_df[new_df['species']=='Alopochen aegyptiaca']\n",
    "moyen = new_new_df['individualCount'].sum()/len(new_new_df)\n",
    "print('moyen : ', moyen)\n",
    "dico_count_ou = {}\n",
    "for ye in year:\n",
    "    data1 = new_new_df[new_new_df['year']==ye]\n",
    "    dico_count_ou[ye]=data1['individualCount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dico_count_ou.keys(),dico_count_ou.values())\n",
    "#plt.title(\"Ratio d'obseervation pour chaque année\")\n",
    "plt.xlabel('Années')\n",
    "plt.ylabel(\"Nombre d'espèce\")\n",
    "#plt.savefig(\"rat_annee.png\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluer général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_df = df_prefixSpan[df_prefixSpan['nombre_annee']>=3]\n",
    "espece = tri_df['espèce'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_croissance = {}\n",
    "for elem in tri_df.itertuples():\n",
    "    compte = elem.compte\n",
    "    somme = 0\n",
    "    count = 0\n",
    "    for i in range(1, len(compte)):\n",
    "        somme += (compte[i]-compte[i-1])/compte[i-1]\n",
    "        count+=1\n",
    "    moyen = somme/count\n",
    "    dico_croissance[elem.espèce]=moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_croissance = pd.DataFrame(dico_croissance.items(), columns=['espèce', 'croissance'])\n",
    "#print(df_croissance[df_croissance['croissance']>0.1])\n",
    "df_croissance.sort_values(by = 'croissance', ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = set(df_outte['year'].tolist())\n",
    "dico_year = {}\n",
    "for ye in year:\n",
    "    data1 = df_outte[df_outte['year']==ye]\n",
    "    dico_year[ye]=len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation (df ,df_prefixSpan, espece):\n",
    "    df_outte = df_prefixSpan[df_prefixSpan['espèce']== frozenset([espece])]\n",
    "    count_ouette = df_outte['compte'].tolist()\n",
    "    annee_ouette = df_outte['année'].tolist()\n",
    "    plt.figure(1)\n",
    "    plt.plot(annee_ouette[0], count_ouette[0])\n",
    "    plt.xlabel('Temps (Années)')\n",
    "    plt.ylabel(\"Observation\")\n",
    "    plt.savefig(\"obs_annee.png\")\n",
    "    plt.show()\n",
    "    print('ratio')\n",
    "    year = set(df['year'].tolist())\n",
    "    dico_year = {}\n",
    "    for ye in year:\n",
    "        data1 = df[df['year']==ye]\n",
    "        dico_year[ye]=len(data1)\n",
    "    new_dic = {}\n",
    "    count = 0\n",
    "    for key,value in dico_year.items():\n",
    "        new_dic[key] = (count_ouette[0][count]/value)*100\n",
    "        count+=1\n",
    "    plt.figure(2)\n",
    "    plt.plot(new_dic.keys(),new_dic.values())\n",
    "    #plt.title(\"Ratio d'observation pour chaque année\")\n",
    "    plt.xlabel('Temps (Années)')\n",
    "    plt.ylabel(\"Observation(%)\")\n",
    "    plt.savefig(\"rat_annee.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation (new_df ,df_prefixSpan, 'Alopochen aegyptiaca')# Alopochen aegyptiaca 'Branta canadensis'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
